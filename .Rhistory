b <- c(2,2,0)
cor(a,b)
a <- c(1,2,3)
b <- c(1,2,3)
cor(a,b)
a <- c(1,2,3)
b <- c(2,1,3)
cor(a,b)
a <- c(1,2,3)
b <- c(2,1,1)
cor(a,b)
a <- c(1,2,3)
b <- c(3,2,1)
cor(a,b)
library(ISLR)
library(e1071)
library(randomForest)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
svmfit.4a.2=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=0.1,cost =1)
dbaDat <- read.table("data_banknote_authentication.txt",sep=",")
colnames(dbaDat) <- c("var","skew","curt","entr","auth")
dbaDat$auth <- factor(dbaDat$auth)
dim(dbaDat)
summary(dbaDat)
head(dbaDat)
pairs(dbaDat[,1:4],col=as.numeric(dbaDat$auth))
library(ISLR)
library(e1071)
library(randomForest)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
dbaDat <- read.table("data_banknote_authentication.txt",sep=",")
colnames(dbaDat) <- c("var","skew","curt","entr","auth")
dbaDat$auth <- factor(dbaDat$auth)
dim(dbaDat)
summary(dbaDat)
head(dbaDat)
pairs(dbaDat[,1:4],col=as.numeric(dbaDat$auth))
dbaDat$auth <- factor(dbaDat$auth)
svmfit.4a.2=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=0.1,cost =1)
plot(svmfit.4a.2, dbaDat[,c(1,2,5)],main="gamma=0.1")
svmfit.4a.3=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=100,cost =1)
plot(svmfit.4a.3, dbaDat[,c(1,2,5)],main="gamma=100")
tune(svm,auth~.,data=dbaDat,kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
xx <- tune(svm,auth~.,data=dbaDat,kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
xx$best.model
xx$best.parameters
xx$best.parameters[[2]]
xx$best.parameters[[1]]
xx$best.parameters
xx$best.parameters[[1]]
xx$best.parameters
xx$best.parameters[[2]]
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[1]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
xvalTesterrSVM.4b(nTries=1,kXval=5)
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[2]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
xvalTesterrSVM.4b(nTries=1,kXval=5)
# whole dataset
knn.tune.out <- tune.knn(x = dbaDat[,-5], y = dbaDat$auth, k = 1:20,tunecontrol=tune.control(sampling = "cross"), cross=10)
summary(knn.tune.out)
# resampling procedure
xvalTesterrKNN<- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
#TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
knn.tune <-tune.knn(x = dbaDat[xvalFolds!=kFold,-5], y = dbaDat[xvalFolds!=kFold,5], k = 1:20 )
auth.predict<- knn(train = dbaDat[xvalFolds!=kFold,-5],test = dbaDat[xvalFolds==kFold,-5],
cl = dbaDat[xvalFolds!=kFold,5],k = knn.tune$best.parameters[[1]])
TestFoldErr <- sum(ifelse(as.numeric(auth.predict)==as.numeric(dbaDat[xvalFolds==kFold,5]),0,1))/nrow(dbaDat[xvalFolds==kFold,])
#retRes <- c(retRes,TestFoldErr)
retRes <- rbind(retRes,data.frame(sim=iTry,TestErr=TestFoldErr,k.tuned=knn.tune$best.parameters[[1]]))
}
}
retRes
}
# 10-fold CV for SVM in cost range from 1 to 20
res <- xvalTesterrKNN(nTries=30,kXval=10)
ggplot(res,aes(x=factor(k.tuned),y=TestErr)) + geom_boxplot()
ggplot(xvalTesterrSVM.4b(nTries=30,kXval=5),aes(x=factor(params),y=testErr)) + geom_boxplot()
ggplot(xvalTesterrSVM.4b(nTries=10,kXval=5),aes(x=factor(params),y=testErr)) + geom_boxplot()
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[2]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
xvalTesterrSVM.4b(nTries=1,kXval=5)
xvalTesterrSVM.4b(nTries=1,kXval=5)
library(ISLR)
library(e1071)
library(randomForest)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
dbaDat <- read.table("data_banknote_authentication.txt",sep=",")
colnames(dbaDat) <- c("var","skew","curt","entr","auth")
dbaDat$auth <- factor(dbaDat$auth)
dim(dbaDat)
summary(dbaDat)
head(dbaDat)
pairs(dbaDat[,1:4],col=as.numeric(dbaDat$auth))
dbaDat$auth <- factor(dbaDat$auth)
svmfit.cost0.001=svm(auth~., dbaDat, kernel="linear", cost=0.001)
summary(svmfit.cost0.001)
svmfit.cost1=svm(auth~., dbaDat, kernel="linear", cost=1)
summary(svmfit.cost1)
svmfit.cost1000=svm(auth~., dbaDat, kernel="linear", cost=1000)
summary(svmfit.cost1000)
svmfit.cost1mln=svm(auth~., dbaDat, kernel="linear", cost=1000000)
summary(svmfit.cost1mln)
set.seed (1)
tune.out=tune(svm, auth~.,data=dbaDat,kernel="linear",ranges=list(cost=c(0.1, 0.3, 0.5, round(exp(log(10)*seq(log10(1),log10(100),by=0.25))))))
summary(tune.out)
xvalTesterrSVM <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
for ( cSelect in seq(3,10,by=0.5) ) {
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.fit <-svm(auth~.,dbaDat[xvalFolds!=kFold,],kernel="linear",cost=cSelect)
auth.predict <- predict(svm.fit,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
}
TestErr <- rbind(TestErr,colMeans(TestFoldErr))
retRes <- rbind(retRes,data.frame(sim=iTry,cost=cSelect,testErr=TestErr))
}
}
retRes
}
# 10-fold CV for SVM in cost range from 3 to 10
res <- xvalTesterrSVM(nTries=30,kXval=10)
ggplot(res,aes(x=factor(cost),y=testErr)) + geom_boxplot()
set.seed(111)
RF <- randomForest(auth~.,dbaDat)
RF$confusion
# whole dataset
knn.tune.out <- tune.knn(x = dbaDat[,-5], y = dbaDat$auth, k = 1:20,tunecontrol=tune.control(sampling = "cross"), cross=10)
summary(knn.tune.out)
# resampling procedure
xvalTesterrKNN<- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
#TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
knn.tune <-tune.knn(x = dbaDat[xvalFolds!=kFold,-5], y = dbaDat[xvalFolds!=kFold,5], k = 1:20 )
auth.predict<- knn(train = dbaDat[xvalFolds!=kFold,-5],test = dbaDat[xvalFolds==kFold,-5],
cl = dbaDat[xvalFolds!=kFold,5],k = knn.tune$best.parameters[[1]])
TestFoldErr <- sum(ifelse(as.numeric(auth.predict)==as.numeric(dbaDat[xvalFolds==kFold,5]),0,1))/nrow(dbaDat[xvalFolds==kFold,])
#retRes <- c(retRes,TestFoldErr)
retRes <- rbind(retRes,data.frame(sim=iTry,TestErr=TestFoldErr,k.tuned=knn.tune$best.parameters[[1]]))
}
}
retRes
}
# 10-fold CV for SVM in cost range from 1 to 20
res <- xvalTesterrKNN(nTries=30,kXval=10)
ggplot(res,aes(x=factor(k.tuned),y=TestErr)) + geom_boxplot()
svmfit.4a=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=1,cost =1)
plot(svmfit.4a, dbaDat[,c(1,2,5)],main="gamma=1")
svmfit.4a.2=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=0.1,cost =1)
plot(svmfit.4a.2, dbaDat[,c(1,2,5)],main="gamma=0.1")
svmfit.4a.3=svm(auth~., data=dbaDat[,c(1,2,5)], kernel="radial", gamma=100,cost =1)
plot(svmfit.4a.3, dbaDat[,c(1,2,5)],main="gamma=100")
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[2]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
# reduce the iterations amount, I use 10 tries here.
ggplot(xvalTesterrSVM.4b(nTries=10,kXval=10),aes(x=factor(params),y=testErr)) + geom_boxplot()
# reduce the iterations amount, I use 5 tries here.
ggplot(xvalTesterrSVM.4b(nTries=5,kXval=10),aes(x=factor(params),y=testErr)) + geom_boxplot()
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[2]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
# reduce the iterations amount, I use 1 tries here.
ggplot(xvalTesterrSVM.4b(nTries=1,kXval=10),aes(x=factor(params),y=testErr)) + geom_boxplot()
xvalTesterrSVM.4b <- function(nTries=10,kXval=5) {
retRes <- NULL
for ( iTry in 1:nTries ) {
xvalFolds <- sample(rep(1:kXval,length.out=nrow(dbaDat)))
TestErr<- NULL
TestFoldErr <- NULL
for ( kFold in 1:kXval ) {
svm.tune.out <- tune(svm,auth~.,data=dbaDat[xvalFolds!=kFold,],kernel="linear",
ranges=list(cost=c(1,2,5,10,20),gamma=c(0.01,0.02,0.05,0.1,0.2)))
auth.predict <- predict(svm.tune.out$best.model,dbaDat[xvalFolds==kFold,])
tbl <- table(predict=auth.predict,truth=dbaDat[xvalFolds==kFold,]$auth)
TestFoldErr <- rbind(TestFoldErr,(tbl[1,2]+tbl[2,1])/nrow(dbaDat[xvalFolds==kFold,]))
retRes <- rbind(retRes,data.frame(sim=iTry,params=paste(svm.tune.out$best.parameters[[1]],svm.tune.out$best.parameters[[2]],sep = "&"),testErr=TestFoldErr))
}
}
retRes
}
# reduce the iterations amount, I use 1 try here.
ggplot(xvalTesterrSVM.4b(nTries=1,kXval=10),aes(x=factor(params),y=testErr)) + geom_boxplot()
# reduce the iterations amount, I use 2 try here.
ggplot(xvalTesterrSVM.4b(nTries=2,kXval=10),aes(x=factor(params),y=testErr)) + geom_boxplot()
load("/Users/tianwang/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
knitr::opts_chunk$set(echo = TRUE)
SVM.assess <- cvSVM(trainDat[,-2], N.xval=2, N.iter=1)
library(e1071)
ResSVMtune$best.parameters
SVM.assess <- cvSVM(trainDat[,-2], N.xval=2, N.iter=1)
View(SVM.assess)
SVM.assess <- cvSVM(trainDat[,-2], N.xval=5, N.iter=3)
View(SVM.assess)
View(SVM.assess)
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
unlist(lapply(RF.assess,mean))
unlist(lapply(SVM.assess,mean))
Assess <- cbind(Assess,data.frame(unlist(lapply(SVM.assess,mean))))
colnames(Assess)[5] <- c("SVM")
Assess
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
Assess
View(ResRF)
View(testDat)
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, testDat[,-1])
# model ResRF is the best model among all four models.
# estimate test dataset.
library(randomForest)
# model ResRF is the best model among all four models.
# estimate test dataset.
library(randomForest)
PreRF <- predict(ResRF, testDat[,-1])
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, testDat[,-1])
PreRF
PreRF$class
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, newdata = testDat[,-1])
PreRF
PreRF[1]
data.frame(PreRF)
data.frame(PreRF)[,1]
Res <- cbind(testDat[,1],data.frame(PreRF)[,1])
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, newdata = testDat[,-1])
Res <- cbind(testDat[,1],data.frame(PreRF)[,1])
View(Res)
colnames(Res) <- c("id","RF.Predict")
head(Res)
Res <- cbind(data.frame(testDat[,1]),data.frame(PreRF)[,1])
colnames(Res) <- c("id","RF.Predict")
head(Res)
View(Res)
# write to .csv
write.csv(Res,"predictions.csv")
View(Res)
Res <- cbind(testDat[,1],data.frame(PreRF)[,1])
colnames(Res) <- c("id","RF.Predict")
head(Res)
# write to .csv
write.csv(Res,"predictions.csv")
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
PreRF
data.frame(PreRF)[,1]
cbind(testDat[,1],data.frame(PreRF)[,1])
data.frame(PreRF)[,1]
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, newdata = testDat[,-1])
PreRF
matrix(PreRF)
matrix(PreRF)[,1]
data.frame(PreRF)
data.frame(PreRF)[,1]
class(data.frame(PreRF)[,1])
resss <- data.frame(PreRF)[,1]
View(testDat)
ids <- testDat$id
Res <- cbind(ids,resss)
View(Res)
resss <- as.factor(data.frame(PreRF)[,1])
ids <- testDat$id
Res <- cbind(ids,resss)
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, newdata = testDat[,-1])
resss <- data.frame(PreRF)[,1]
resss <- data.frame(PreRF)[,1]
# model ResRF is the best model among all four models.
# estimate test dataset.
PreRF <- predict(ResRF, newdata = testDat[,-1])
PreRF
data.frame(PreRF)[,1]
Res <- cbind(ids,data.frame(PreRF)[,1])
View(Res)
Res <- data.frame(cbind(ids,data.frame(PreRF)[,1]))
View(Res)
View(Res)
PreRF
Res$V2 <- ifelse(Res$V2==1,"no","yes")
PreRF
rm(resss)
rm(ids)
Res <- data.frame(cbind(testDat$id,data.frame(PreRF)[,1]))
Res$V2 <- ifelse(Res$V2==1,"no","yes")
View(Res)
Res$X2 <- ifelse(Res$X2==1,"no","yes")
colnames(Res) <- c("id","RF.Predict")
head(Res)
# write to .csv
write.csv(Res,"predictions.csv",row.names=FALSE)
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
PreRF
tail(PreRF)
PreRF
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
cvQDA = function(Dat, N.xval=10, N.iter=100){
# empty lists to store accuracy, error, sensitivity, and specificity of each trial.
accuracy <- numeric(N.iter)
error <- numeric(N.iter)
sensitivity <- numeric(N.iter)
specificity <- numeric(N.iter)
# accuracy/error/sensitivity/specificity in each cross validation.
M.accuracy <- numeric(N.xval)
M.error <- numeric(N.xval)
M.sensitivity <- numeric(N.xval)
M.specificity <- numeric(N.xval)
for ( iter in 1:N.iter ) {
grps= sample( (1:nrow(Dat)) %% N.xval+1 )
for ( i in 1:N.xval ) { # for each group:
Dat.test = Dat[grps==i,] #set it as test
Dat.train = Dat[grps != i,] # set the rest as train
QDAM <-  qda(noyes~.,Dat.train)
M.p <- predict(QDAM,newdata=Dat.test)$class
tbl <- table("PRE"=M.p,"TRUE"=Dat.test$noyes)
M.accuracy[i] <- (tbl[1,1]+tbl[2,2])/nrow(Dat.test)
M.error[i] <- (tbl[1,2]+tbl[2,1])/nrow(Dat.test)
M.sensitivity[i] <- tbl[2,2]/(tbl[1,2]+tbl[2,2])
M.specificity[i] <- tbl[1,1]/(tbl[1,1]+tbl[2,1])
}
accuracy[iter] <- mean(M.accuracy)
error[iter] <- mean(M.error)
sensitivity[iter] <- mean(M.sensitivity)
specificity[iter] <- mean(M.specificity)
}
l = list(accuracy,error,sensitivity,specificity)
names(l) = paste("QDA",c(".accuracy",".error",".sens",".spec"),sep="")
return( l )
}
# use the dummy coded training dataset "trainDat.Dummy.LR" as input dataset.
QDA.assess <- cvQDA(trainDat.Dummy.LR, N.xval=10, N.iter=30)
library(MASS)
library(MASS)
# use the dummy coded training dataset "trainDat.Dummy.LR" as input dataset.
QDA.assess <- cvQDA(trainDat.Dummy.LR, N.xval=10, N.iter=30)
Assess <- data.frame(unlist(lapply(LR.assess,mean)))
rownames(Assess) <- c("accuracy","error","sensitivity","specificity")
Assess <- cbind(Assess,data.frame(unlist(lapply(LDA.assess,mean))))
colnames(Assess) <- c("LR","LDA")
Assess
Assess <- cbind(Assess,data.frame(unlist(lapply(QDA.assess,mean))))
colnames(Assess)[3] <- c("QDA")
Assess
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
library(e1071)
library(randomForest)
library(MASS)
Assess <- cbind(Assess,data.frame(unlist(lapply(RF.assess[1:4],mean))))
colnames(Assess)[4] <- c("RF")
Assess
Assess <- cbind(Assess,data.frame(unlist(lapply(SVM.assess,mean))))
colnames(Assess)[5] <- c("SVM")
Assess
Assess
save.image("~/Dropbox/HES/CS-63/CS-63-Final/Untitled.RData")
library(devtools)
library(devtools)
devtools::install_github("twangxxx/netZoo")
devtools::install_github("twangxxx/netZoo",force = T)
library(netZoo)
?runPanda
treated_expression_file_path <- system.file("extdata", "expr4.txt", package = "netZoo", mustWork = TRUE)
control_expression_file_path <- system.file("extdata", "expr10.txt", package = "netZoo", mustWork = TRUE)
motif_file_path <- system.file("extdata", "chip.txt", package = "netZoo", mustWork = TRUE)
ppi_file_path <- system.file("extdata", "ppi.txt", package = "netZoo", mustWork = TRUE)
treated_all_panda_result <- runPanda(e = treated_expression_file_path, m = motif_file_path, ppi = ppi_file_path, rm_missing = TRUE )
treated_all_panda_result <- runPanda(e = treated_expression_file_path, m = motif_file_path, ppi = ppi_file_path, rm_missing = TRUE )
control_all_panda_result <- runPanda(e = control_expression_file_path, m = motif_file_path, ppi = ppi_file_path, rm_missing = TRUE )
control_net <- control_all_panda_result$panda
runCytoscapePlot(control_net, top = 200, network.name="TB_control")
plotPANDAinCytoscap(control_net, top = 200, network.name="TB_control")
plotPANDAinCytoscape(control_net, top = 200, network.name="TB_control")
plotPANDAinCytoscape(control_net, network.name="TB_control")
View(control_net)
plotPANDAinCytoscape(control_net[c(1:2000),], network.name="TB_control")
plotPANDAinCytoscape(control_net[c(1:2000),], network.name="TB_control")
createPandaStyle()
devtools::install_github("twangxxx/netZoo",force = T)
library(netZoo)
?runPanda
setwd("~/Documents/GitHub/netZoo-devel/")
getwd()
setwd("~/Documents/GitHub/netZoo-devel/")
getwd()
setwd("~/Documents/GitHub/netZoo-devel/")
setwd("~/Documents/GitHub/netZoo-devel/")
getwd()
setwd("./Documents/GitHub/netZoo-devel/")
setwd("~/Documents/GitHub/netZoo_devel/")
library(devtools)
library(roxygen2)
build()
document()
setwd("..")
install()
setwd("~/Documents/GitHub/netZoo_devel/")
install()
?runPanda
remove.packages("netZooR")
remove.packages("netZoo")
setwd("~/Documents/GitHub/netZoo_devel/")
build()
document()
setwd("~/Documents/GitHub/netZoo_devel/")
build()
document()
document()
install()
setwd("~/Documents/GitHub/netZoo_devel/")
library(devtools)
library(roxygen2)
build()
document()
